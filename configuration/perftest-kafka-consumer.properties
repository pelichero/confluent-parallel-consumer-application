
# KafkaConsumer properties
# increase max.poll.records from default of 500 to ensure we can download many records
max.poll.records=10000
# large fetch.min.bytes to optimize for throughput
fetch.min.bytes=100000

# Application-specific properties
input.topic=perftest-parallel-consumer-input-topic
records.to.consume=10000
record.handler.sleep.ms=20
# Consumer properties
bootstrap.servers=localhost:29092
key.deserializer=org.apache.kafka.common.serialization.StringDeserializer
value.deserializer=org.apache.kafka.common.serialization.StringDeserializer
max.poll.interval.ms=300000
enable.auto.commit=false
auto.offset.reset=earliest

# Application-specific properties
input.topic.name=parallel-consumer-input-topic
file.path=topic-output.txt
